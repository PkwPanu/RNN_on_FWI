{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function   \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from keras import Input, layers, activations, backend ,optimizers\n",
    "from keras.models import  Model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "def ricker(f0,t):\n",
    "    f=f0\n",
    "    r=-(np.pi*f*(t-0.1))**2\n",
    "    return (1+2*r)*(np.e)**r\n",
    "\n",
    "\n",
    "def velocity_profile(size,npml,dx):\n",
    "    layer=[220,450,700,]  #  position of boundary [meter] \n",
    "    velocity=[2000,3000,4000,5000] # m/s  \n",
    "    nx=int((size+2*npml)/dx)\n",
    "    layer=np.array(layer)+npml\n",
    "    v=np.zeros(nx)\n",
    "    k0=0\n",
    "    for j,i in enumerate(layer):\n",
    "        k1=int(i/dx)\n",
    "        v[k0:k1]=velocity[j]\n",
    "        k0=k1\n",
    "        \n",
    "    v[k0:]=velocity[j+1]  \n",
    "    return v\n",
    "\n",
    "\n",
    "def data_gen(f0,totaltime,Dimension,PMLsize,dx,rp,sp,timeskip,v):\n",
    "    global a_x,b_x,a_x_half,b_x_half,energy\n",
    "\n",
    "    TT=totaltime #time (second)\n",
    "\n",
    "    Dimension=Dimension+2*PMLsize\n",
    "    nodepml= int(PMLsize/dx)\n",
    "\n",
    "\n",
    "    nx=int(np.round(Dimension/dx))\n",
    "    #v = velocity_profile(nx,PMLsize) \n",
    "    vmax=max(v)\n",
    "    dt=dx/vmax\n",
    "    NT=int(np.round(TT/dt))\n",
    "    \n",
    "    energy=np.zeros(NT)\n",
    "\n",
    "    # PML \n",
    "    Xorigin_left= PMLsize #size of PML (meter)\n",
    "    Xorigin_right=(nx-1)*dx-Xorigin_left\n",
    "\n",
    "    ALPHA_MAX_PML=np.pi*f0;\n",
    "    #NN=2\n",
    "    #Rc=0.001\n",
    "    #d0_x=-(NN+1)*vmax*np.log(Rc)/(2*Xorigin_left)\n",
    "    d0_x=9*vmax/(2*Xorigin_left)\n",
    "\n",
    "    d_x=np.zeros(nx)\n",
    "    d_x_half=np.zeros(nx)\n",
    "    #K_x=np.ones(nx)\n",
    "    #K_x_half=np.ones(nx)\n",
    "    alpha_x=np.zeros(nx)\n",
    "    alpha_x_half=np.zeros(nx)\n",
    "    a_x=np.zeros(nx)\n",
    "    a_x_half=np.zeros(nx)\n",
    "    b_x=np.zeros(nx)\n",
    "    b_x_half=np.zeros(nx)\n",
    "\n",
    "\n",
    "    #saving data\n",
    "    Y=[]  #wave at reciever\n",
    "    So=np.zeros([NT]) #source\n",
    "\n",
    "\n",
    "    # reciever positions \n",
    "    rp=rp+PMLsize  \n",
    "    rp=int(rp/dx)\n",
    "\n",
    "    # sorce position\n",
    "\n",
    "    sp=sp+PMLsize \n",
    "    Sp=np.zeros(nx)\n",
    "    Sp[int(sp/dx)]=1\n",
    "\n",
    "    # prepare coff\n",
    "    for i in range(nx):\n",
    "        xval=i*dx\n",
    "\n",
    "        #Xmin\n",
    "        absci=Xorigin_left-xval\n",
    "        if absci >=0 :\n",
    "            abscissa_normalized=absci/Xorigin_left\n",
    "            d_x[i]=d0_x*(abscissa_normalized**2) \n",
    "            alpha_x[i]=ALPHA_MAX_PML*(1-abscissa_normalized)\n",
    "\n",
    "        absci=Xorigin_left-(xval+dx/2)\n",
    "        if absci >=0 :\n",
    "            abscissa_normalized=absci/Xorigin_left\n",
    "            d_x_half[i]=d0_x*(abscissa_normalized**2)\n",
    "            alpha_x_half[i]=ALPHA_MAX_PML*(1-abscissa_normalized)\n",
    "\n",
    "        #Xmax\n",
    "        absci=xval-Xorigin_right\n",
    "        if absci >=0 :\n",
    "            abscissa_normalized=absci/Xorigin_left\n",
    "            d_x[i]=d0_x*(abscissa_normalized**2)\n",
    "            alpha_x[i]=ALPHA_MAX_PML*(1-abscissa_normalized)\n",
    "\n",
    "        absci=xval+dx/2-Xorigin_right\n",
    "        if absci >=0 :\n",
    "            abscissa_normalized=absci/Xorigin_left\n",
    "            d_x_half[i]=d0_x*(abscissa_normalized**2)\n",
    "            alpha_x_half[i]=ALPHA_MAX_PML*(1-abscissa_normalized)\n",
    "\n",
    "\n",
    "        b_x[i] = np.exp(- (d_x[i]  + alpha_x[i]) * dt)\n",
    "        b_x_half[i] = np.exp(- (d_x_half[i]  + alpha_x_half[i]) * dt)\n",
    "        \n",
    "       \n",
    "        if abs(d_x[i]) >1e-6 :\n",
    "            #a_x[i] = d_x[i] * (b_x[i] - 1) / (K_x[i] * (d_x[i] + K_x[i] * alpha_x[i]))\n",
    "            a_x[i] = d_x[i] * (b_x[i] - 1) / (d_x[i] +  alpha_x[i])\n",
    "        if abs(d_x_half[i]) > 1e-6: \n",
    "            #a_x_half[i] = d_x_half[i] * (b_x_half[i] - 1) / (K_x_half[i] * (d_x_half[i] + K_x_half[i] * alpha_x_half[i]))\n",
    "            a_x_half[i] = d_x_half[i] * (b_x_half[i] - 1) / (d_x_half[i] + alpha_x_half[i])\n",
    "    mpx=np.zeros(nx)\n",
    "    mpxx=np.zeros(nx)\n",
    "    vpx=np.zeros(nx)\n",
    "    vpxx=np.zeros(nx)\n",
    "    pxx=np.zeros(nx)\n",
    "    dpxx=np.zeros(nx)\n",
    "    u0=np.zeros(nx)\n",
    "    u1=np.zeros(nx)\n",
    "    u2=np.zeros(nx)\n",
    "\n",
    "    kappa=(v**2)*dt*dt/dx/dx\n",
    "    vsource=kappa[int(sp/dx)]*dx*dx\n",
    "    \n",
    "    iii=0\n",
    "    for it in range(NT):\n",
    "        \n",
    "        So[it]=ricker(f0,it*dt)*vsource\n",
    "        \n",
    "        if it%timeskip==0:       \n",
    "            Y=np.append(Y,u1[rp])           \n",
    "            \n",
    "        vpx[:-1]=(u1[1:]-u1[:-1])\n",
    "        mpx = b_x_half*mpx+a_x_half*vpx\n",
    "        pxx= vpx+mpx\n",
    "\n",
    "        vpxx[1:]= (pxx[1:]-pxx[:-1])\n",
    "        mpxx = b_x*mpxx+a_x*vpxx \n",
    "        dpxx= vpxx+mpxx\n",
    "\n",
    "        u2=2*u1-u0+kappa*dpxx-Sp*So[it]\n",
    "        u2[0]=0\n",
    "        u2[-1]=0    \n",
    "\n",
    "        u0[:]=u1[:]\n",
    "        u1[:]=u2[:]  \n",
    "        \n",
    "        #energy[it]=np.sum(0.5*u1*u1*v*v/1000000)\n",
    "        \n",
    "    return So,Y,NT,nx,dt\n",
    "\n",
    "\n",
    "def kerF(n,var):\n",
    "    x = np.linspace(-5,5,n)\n",
    "    x = np.exp(-0.5*((x/var)**2))\n",
    "    x = x/(var*((2*np.pi)**0.5))\n",
    "    return x\n",
    "\n",
    "def smoothV(v,kernel_dimension,kerne_variace):\n",
    "    kernel=kerF(kernel_dimension,kerne_variace)\n",
    "    kernel=kernel/np.sum(kernel)\n",
    "    k_smooth=np.empty(v.size)\n",
    "    k1=v[0]*np.ones(int((kernel_dimension-1)/2))\n",
    "    k2=v[-1]*np.ones(int((kernel_dimension-1)/2))\n",
    "    k_extend=np.append(k1,v)\n",
    "    k_extend=np.append(k_extend,k2)\n",
    "    for i in range(v.size):\n",
    "        k_smooth[i]=np.dot(kernel,k_extend[i:i+kernel_dimension])\n",
    "    return k_smooth\n",
    "\n",
    "\n",
    "# model\n",
    "def customRelu1(x):\n",
    "    x=activations.relu(x,alpha=0.0, max_value=1.0, threshold=0.0)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def MLaplace(u1,mpx,mpxx):\n",
    "        vpx = DRlayers(u1)\n",
    "        mpx1 = Mlayers([input_bh,mpx])\n",
    "        mpx2 = Mlayers([input_ah,vpx])\n",
    "        mpx = Alayers([mpx1,mpx2])\n",
    "        pxx = Alayers([vpx,mpx])\n",
    "\n",
    "        vpx = DLlayers(pxx)\n",
    "        mpx1 = Mlayers([input_b,mpxx])\n",
    "        mpx2 = Mlayers([input_a,vpx])\n",
    "        mpxx = Alayers([mpx1,mpx2])\n",
    "        pxx = Alayers([vpx,mpxx])\n",
    "    \n",
    "        return pxx,mpx,mpxx\n",
    "\n",
    "def wave(u0,u1,pxx,source):\n",
    "        x = Mlayers([pxx,velocitylocal])\n",
    "        uu1= Alayers([u1,u1])\n",
    "        x = Alayers([x,uu1])\n",
    "        u2 = Slayers([x,u0])    \n",
    "        u2 = Slayers([u2,source])    \n",
    "        u2 = Mlayers([u2,input_BC])\n",
    "        return u1,u2 \n",
    "\n",
    "def read(trace,s,u1,timeskip,i):\n",
    "        if i%timeskip==0 :\n",
    "            value=Players(u1) \n",
    "            trace = Clayers([trace,value])     \n",
    "            \n",
    "        sourcei = Pickfunction(s)  \n",
    "        s=CropS(s)     \n",
    "        return trace,s,sourcei\n",
    "    \n",
    "def repeat(x):\n",
    "    return backend.repeat_elements(x,rep=npml, axis=1)\n",
    "\n",
    "def PML_pad(x):\n",
    "    xl=PML_PickL(x)\n",
    "    xr=PML_PickR(x)\n",
    "    xl= PML_repeat(xl)\n",
    "    xr= PML_repeat(xr) \n",
    "    return Clayers([xl,x,xr]) \n",
    "\n",
    "\n",
    "def create_network(nx,nt,dx,dt,Rp,timeskip):  \n",
    "    \n",
    "    global DLlayers,DRlayers,Alayers,Mlayers,Slayers,Clayers,Players,CropS,Pickfunction,PML_PickL,PML_PickR,PML_repeat\n",
    "    global input_a,input_b,input_ah,input_bh, input_BC\n",
    "    global velocitylocal\n",
    "    \n",
    "     \n",
    "    constants =  np.zeros([1,nx,1],dtype=np.float32)\n",
    "    fixed_input0 = Input(shape=(nx,1),tensor=tf.constant(constants))\n",
    "    \n",
    "    constants =  a_x.astype(np.float32).reshape(nx,1)\n",
    "    input_a = Input(shape=(nx,1),tensor=tf.constant(constants))\n",
    "    \n",
    "    constants =  b_x.astype(np.float32).reshape(nx,1)\n",
    "    input_b = Input(shape=(nx,1),tensor=tf.constant(constants))\n",
    "    \n",
    "    constants =  a_x_half.astype(np.float32).reshape(nx,1)\n",
    "    input_ah =Input(shape=(nx,1),tensor=tf.constant(constants))\n",
    "   \n",
    "    constants =  b_x_half.astype(np.float32).reshape(nx,1)\n",
    "    input_bh =Input(shape=(nx,1),tensor=tf.constant(constants))   \n",
    "   \n",
    "    constants=np.ones([nx])\n",
    "    constants[0]=0 \n",
    "    constants[-1]=0\n",
    "    constants=constants.astype(np.float32).reshape(nx,1)\n",
    "    input_BC = Input(shape=(nx,1),tensor=tf.constant(constants))    \n",
    "    \n",
    "    constants= np.ones([1,1])*dt/dx\n",
    "    constants=constants.astype(np.float32)\n",
    "    input_c = Input(shape=(1,1),tensor=tf.constant(constants)) \n",
    "    \n",
    "    input_s = Input(shape=(nx,nt,1),name=\"Input_s\") # source\n",
    "    \n",
    "\n",
    "    #layer\n",
    "    wR=np.array([[[0]],[[-1]],[[1]]])\n",
    "    wL=np.array([[[-1]],[[1]],[[0]]])\n",
    "    \n",
    "    DLlayers=layers.Conv1D(1,3,padding='same', activation=None,weights=[wL],use_bias=False,trainable=False,name='DL')\n",
    "    DRlayers=layers.Conv1D(1,3,padding='same', activation=None,weights=[wR],use_bias=False,trainable=False,name='DR')\n",
    "    \n",
    "    \n",
    "    I = layers.Lambda(lambda x: x,name='Identity',trainable=False)\n",
    "    Alayers = layers.Add(name='Add',trainable=False)\n",
    "    Mlayers = layers.Multiply(name='Multiply',trainable=False)\n",
    "    Slayers = layers.Subtract(name='Subtract',trainable=False)\n",
    "    Clayers = layers.Concatenate(axis=1,name='Concate',trainable=False)\n",
    "    \n",
    "    nnode=int(nx-2*npml)\n",
    "    Players = layers.Lambda(lambda x: x[:,Rp:Rp+1],name=\"Pick_data\",trainable=False)    #reciever \n",
    "    Local=layers.Dense(nnode,activation=customRelu1,use_bias=False,name='local_velocity')\n",
    "    CropS=layers.Lambda(lambda x: x[:,:,1:,:],name=\"Crop_source\",trainable=False)\n",
    "    Pickfunction = layers.Lambda(lambda x: x[:,:,0:1,0],output_shape=[nx,1],name=\"Pick_source\",trainable=False)\n",
    "    \n",
    "    PML_PickL = layers.Lambda(lambda x: x[:,0:1,0:],output_shape=[1,1],trainable=False) \n",
    "    PML_PickR = layers.Lambda(lambda x: x[:,-1:,0:],output_shape=[1,1],trainable=False) \n",
    "    PML_repeat = layers.Lambda(repeat,trainable=False)\n",
    "    \n",
    "    \n",
    "    # initial \n",
    "    velocitylocal = Local(input_c)\n",
    "    velocitylocal =  layers.Reshape([nnode,1],trainable=False)(velocitylocal)\n",
    "    #velocitylocal = layers.UpSampling1D(size=2)(velocitylocal)\n",
    "    velocitylocal = PML_pad(velocitylocal)\n",
    "    velocitylocal = Mlayers([velocitylocal,velocitylocal])\n",
    "    \n",
    "    u0 = I(fixed_input0)\n",
    "    mpx= I(fixed_input0)\n",
    "    mpxx= I(fixed_input0)\n",
    "\n",
    "    #first time step (consider u0,mpx,mpxx =0)\n",
    "    trace = Players(u0)\n",
    "    source = Pickfunction(input_s)\n",
    "    stotal= CropS(input_s)\n",
    "    u1 = Alayers([u0,source]) \n",
    "    u1 = Mlayers([u1,input_BC])\n",
    "    \n",
    "    for i in range(1,nt):\n",
    "        [trace,stotal,source]=read(trace,stotal,u1,timeskip,i)\n",
    "        [pxx,mpx,mpxx] = MLaplace(u1,mpx,mpxx)             \n",
    "        [u0,u1] = wave(u0,u1,pxx,source)       \n",
    "\n",
    "    output_tensor = I(trace)  # wave_field at recievers\n",
    "\n",
    "    model = Model([input_c,input_a,input_b,input_ah,input_bh, input_s,input_BC,fixed_input0], output_tensor)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import interpolate\n",
    "data = np.loadtxt('mar-vel.dat')\n",
    "data = np.reshape(data,[data.size])\n",
    "data = np.transpose(np.reshape(data[:-4],[116,76]))\n",
    "plt.imshow(data)\n",
    "plt.show()\n",
    "\n",
    "X = np.linspace(0,3000,76)\n",
    "Y = np.linspace(0,9200,116)\n",
    "f_vmar = interpolate.interp2d(Y,X,data,kind='linear')\n",
    "\n",
    "Xnew =  np.linspace(0,3000,int(3000/25))\n",
    "Ynew = np.linspace(0,9200,int(9200/25))\n",
    "vmar=f_vmar(Ynew,Xnew)\n",
    "print(vmar.shape)\n",
    "plt.imshow(vmar)\n",
    "plt.show()\n",
    "\n",
    "Xnew0 =  np.linspace(0,3000,int(80))\n",
    "Ynew0 = np.linspace(0,9200,int(9200/25))\n",
    "vmar0=f_vmar(Ynew0,Xnew0)\n",
    "\n",
    "v2=vmar0[:,int(6500/25)]\n",
    "plt.plot(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v02.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3000/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter \n",
    "global npml,nPhyx\n",
    "\n",
    "totaltime= 1   #[second] total time\n",
    "dimension=1000    #[meter]     Dimension\n",
    "PML_size=75           #[meter]     PML layer  \n",
    "dx= 12.5             #[meter]     dx\n",
    "f0= 14                       #[Hz]   peak source frequency \n",
    "rp= 80                      #[meter]   reciever position \n",
    "sp= 100                    #[meter]  source position \n",
    "timeskip= 5               # [n x dt] time sampling, 5 == 5*dt (n == n*dt) \n",
    "\n",
    "\n",
    "#generate data\n",
    "#v0=model1.layers[numlayer['local_velocity']].get_weights()\n",
    "#v0=np.array(v_network).reshape(int(nx_real))\n",
    "#v1=np.pad(v0, int(PML_size/dx), mode='edge')\n",
    "#[So1,Seismogram1,nt1,nx1,dt1]=data_gen(f0,totaltime,dimension,PML_size,dx,rp,sp,timeskip,v1)\n",
    "\n",
    "v = velocity_profile(dimension,PML_size,dx) \n",
    "\n",
    "#v=np.pad(v2, int(PML_size/dx), mode='edge')\n",
    "[So,Seismogram,nt,nx,dt]=data_gen(f0,totaltime,dimension,PML_size,dx,rp,sp,timeskip,v)\n",
    "\n",
    "# create smooth initial velocity profile \n",
    "kernel_dimension=int((20*12.5)/dx +1) # dimension of smooth function\n",
    "kerne_variace=2.8    # width of smooth function\n",
    "v_smooth=smoothV(v,kernel_dimension,kerne_variace)\n",
    "\n",
    "#create network\n",
    "print('creating network ... ')\n",
    "npml = int(round(PML_size/dx))\n",
    "nx_real = int(nx-2*npml)\n",
    "\n",
    "model1=create_network(nx,nt,dx,dt,int((rp+PML_size)/dx),timeskip)   #need pml parameter(global parameters) from data_gen function  \n",
    "print('network is created.')\n",
    "\n",
    "#create dictionary for model layers\n",
    "numlayer={}\n",
    "for i,l in enumerate(model1.layers):\n",
    "    numlayer[l.name] = i\n",
    "    #print(i,l.name, l.trainable) \n",
    "\n",
    "#set initial velocity to smooth\n",
    "a=np.array(model1.layers[numlayer['local_velocity']].get_weights()).shape\n",
    "model1.layers[numlayer['local_velocity']].set_weights(v_smooth[npml:-npml].reshape(a))\n",
    "\n",
    "#change data shape in order to suit input, output shape of network\n",
    "input_s0=np.zeros([1,nx,nt,1])\n",
    "input_s0[0,int((sp+PML_size)/dx),:,0]=So[:]\n",
    "yyyy=Seismogram.reshape([1,Seismogram.size,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numlayer={}\n",
    "for i,l in enumerate(model1.layers):\n",
    "    #numlayer[l.name] = i\n",
    "    print(i,l.name, l.trainable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_predict=model1.predict(x=input_s0)\n",
    "print(v_predict.shape)\n",
    "v_predict0=np.array(v_predict).reshape([v_predict.shape[1]])\n",
    "#v_predict0=np.repeat(v_predict0,2)\n",
    "print(v_predict0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "\n",
    "print('the number of node = ',nx)\n",
    "print('time steps (irteration) = ',nt)\n",
    "print('data sampling = ',Seismogram.size)\n",
    "print('sampling time = ',timeskip*dt*1000, ' ms')\n",
    "plt.plot(np.linspace(0,totaltime,Seismogram.size),Seismogram)\n",
    "#plt.plot(np.linspace(0,totaltime,Seismogram.size),Seismogram1,label='Predicted')\n",
    "#plt.plot(Seismogram[15:],label='True seismogram')\n",
    "#plt.plot(Seismogram1[15:],label='Predicted')\n",
    "\n",
    "plt.ylabel('amplitude', fontsize=15)\n",
    "plt.xlabel(' time (s) ', fontsize=15)\n",
    "plt.legend()\n",
    "plt.savefig('seimogram1.png')\n",
    "plt.show()\n",
    "#x=np.arange(-PML_size,dimension+PML_size,dx)    \n",
    "#plt.plot(x,v,label= 'true velocity')\n",
    "#plt.plot(x,v_smooth,label= 'initial')\n",
    "#plt.legend()\n",
    "x=np.arange(0,dimension,dx)    \n",
    "plt.plot(x,v[npml:-npml])\n",
    "#plt.plot(x,v1[npml:-npml])\n",
    "plt.ylabel('velocity (m/s)', fontsize=15)\n",
    "plt.xlabel(' depth (m) ', fontsize=15)\n",
    "plt.savefig('vmodel1.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.linspace(0,totaltime,nt),So)\n",
    "#plt.plot(x,v1[npml:-npml])\n",
    "plt.ylabel(' amplitude ', fontsize=15)\n",
    "plt.xlabel(' time (s) ', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with ture velocity \n",
    "\n",
    "a=np.array(model1.layers[numlayer['local_velocity']].get_weights()).shape\n",
    "model1.layers[numlayer['local_velocity']].set_weights(v[npml:-npml].reshape(a))\n",
    "\n",
    "model1.compile(optimizer=tf.optimizers.Adam(lr=40), loss='mse') \n",
    "model1.evaluate(x=input_s0,y=yyyy)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(v[npml:-npml])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set initial new velocity profile\n",
    "a=np.array(model1.layers[numlayer['local_velocity']].get_weights()).shape\n",
    "model1.layers[numlayer['local_velocity']].set_weights(v_smooth[npml:-npml].reshape(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=[1,5,40,100]\n",
    "velocity_misfit1 = np.zeros([4,11])\n",
    "x0=np.linspace(0,5000,11)\n",
    "for i in range(4):\n",
    "\n",
    "    a=np.array(model1.layers[numlayer['local_velocity']].get_weights()).shape\n",
    "    model1.layers[numlayer['local_velocity']].set_weights(v_smooth[npml:-npml].reshape(a))\n",
    "    \n",
    "    model1.compile(optimizer=tf.optimizers.Adam(lr=learning_rate[i]), loss='mse') \n",
    "    \n",
    "    for j in range(10):\n",
    "        v_network=model1.layers[numlayer['local_velocity']].get_weights()\n",
    "        v_network=np.array(v_network).reshape([nx_real])\n",
    "        v_network=np.minimum(v_network,np.ones(nx_real)*5000)\n",
    "        velocity_misfit1[i,j]=sum(abs(v_network-v[npml:-npml]))/nx_real\n",
    "        print(i,j,velocity_misfit1[i,j])\n",
    "        history=model1.fit(x=input_s0,y=yyyy,epochs=500,verbose=0)   \n",
    "        \n",
    "    v_network=model1.layers[numlayer['local_velocity']].get_weights()\n",
    "    v_network=np.array(v_network).reshape([nx_real])\n",
    "    v_network=np.minimum(v_network,np.ones(nx_real)*5000)\n",
    "    velocity_misfit1[i,10]=sum(abs(v_network-v[npml:-npml]))/nx_real    \n",
    "    print(i,10,velocity_misfit1[i,10])\n",
    "    \n",
    "for i in range(4):\n",
    "    label0='lr = '\n",
    "    label0 = label0+str(learning_rate[i])\n",
    "    plt.plot(x0,velocity_misfit1[i,:],'o-',label= label0)\n",
    "plt.legend()    \n",
    "plt.ylabel(' velocity error (m/s) ', fontsize=15)\n",
    "plt.xlabel(' epoch ', fontsize=15)\n",
    "plt.savefig('new003.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=[1,5,40,100]\n",
    "loss = np.zeros([4,5000])\n",
    "for i in range(0,4):\n",
    "    \n",
    "    a=np.array(model1.layers[numlayer['local_velocity']].get_weights()).shape\n",
    "    model1.layers[numlayer['local_velocity']].set_weights(v_smooth[npml:-npml].reshape(a))\n",
    "    \n",
    "    model1.compile(optimizer=tf.optimizers.Adam(lr=learning_rate[i]), loss='mse') \n",
    "    print(i)\n",
    "    history=model1.fit(x=input_s0,y=yyyy,epochs=5000,verbose=0)   \n",
    "    loss[i,:]=history.history['loss']\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0=np.arange(1,5000,250)\n",
    "for i in range(4):\n",
    "    label0='lr = '\n",
    "    label0 = label0+str(learning_rate[i])\n",
    "    plt.plot(x0,np.log10(loss[i,:])[::250],'-o',label= label0)\n",
    "    plt.legend()    \n",
    "    plt.ylabel(' $log_{10}$(loss) ', fontsize=15)\n",
    "    plt.xlabel(' epoch ', fontsize=15)\n",
    "plt.savefig('loss001.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss[i,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.arange(1,10)\n",
    "print(a[::3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    label0='lr = '\n",
    "    label0 = label0+str(learning_rate[i])\n",
    "    plt.plot(x0,velocity_misfit1[i,:],'o-',label= label0)\n",
    "plt.legend()    \n",
    "plt.ylabel(' velocity error (m/s) ', fontsize=15)\n",
    "plt.xlabel(' epoch ', fontsize=15)\n",
    "plt.savefig('new01.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    label0='lr = '\n",
    "    label0 = label0+str(learning_rate[i])\n",
    "    plt.plot(velocity_misfit[i,:],label= label0)\n",
    "plt.legend()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer=optimizers.Adam(lr=100), loss='mse') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train  \n",
    "history=model1.fit(x=input_s0,y=yyyy,epochs=500,verbose=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_network=model1.layers[numlayer['local_velocity']].get_weights()\n",
    "v_network=np.array(v_network).reshape(int(nx_real))\n",
    "v_network=np.minimum(v_network,np.ones(nx_real)*5000)\n",
    "#plot\n",
    "x=np.linspace(0,1000,int(nx_real))\n",
    "plt.plot(x,v_network,label= 'predicted velocity')\n",
    "plt.plot(x,v[npml:-npml],label= 'true velocity')  \n",
    "plt.plot(x,v_smooth[npml:-npml], '--', label= 'initial velocity')  \n",
    "plt.legend()\n",
    "plt.ylabel(' velocity (m/s)', fontsize=15)\n",
    "plt.xlabel(' depth (m) ', fontsize=15)\n",
    "#plt.savefig('m1lr100ep5000.png')\n",
    "sum(abs(v_network-v[npml:-npml]))/nx_real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case that we want to try other initial velocity  !!!!!!\n",
    "\n",
    "kernel_dimension=20*8+1  # dimension of smooth function\n",
    "kerne_variace=10    # width of smooth function\n",
    "v_smooth2=smoothV(v,kernel_dimension,kerne_variace)\n",
    "\n",
    "#v_smooth=np.ones(v_smooth.shape)*np.mean(v)\n",
    "\n",
    "#plot\n",
    "x=np.arange(-PML_size,dimension+PML_size,dx)    \n",
    "plt.plot(x,v)\n",
    "plt.plot(x,v_smooth2)\n",
    "plt.show()\n",
    "\n",
    "#set initial new velocity profile\n",
    "a=np.array(model1.layers[numlayer['local_velocity']].get_weights()).shape\n",
    "model1.layers[numlayer['local_velocity']].set_weights(v_smooth2[npml:-npml].reshape(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=(4,)) \n",
    "\n",
    "\n",
    "x = layers.Dense(4)(input_1)  \n",
    "\n",
    "for i in range(3):\n",
    "    x = layers.Dense(4)(x)  \n",
    "\n",
    "model1 = Model([input_1], x)\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=(4,)) \n",
    "\n",
    "A=layers.Dense(4)\n",
    "\n",
    "x = A(input_1)  \n",
    "\n",
    "for i in range(3):\n",
    "    x = A(x)  \n",
    "\n",
    "model2 = Model([input_1], x)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rp=2\n",
    "\n",
    "#constants =  np.zeros([5,1],dtype=np.float32)\n",
    "#fixed_input0 = Input(shape=(5,1),tensor=tf.constant(constants))\n",
    "\n",
    "I = layers.Lambda(lambda x: x,name='Identity',trainable=False)\n",
    "#Players = layers.Lambda(lambda x: x[:,Rp:Rp+1],name=\"Pick_data\",trainable=False)    #reciever \n",
    "#Pickfunction = layers.Lambda(lambda x: x[:,:,0:1,0],output_shape=[nx,1],name=\"Pick_source\",trainable=False)\n",
    "\n",
    "input_1 = Input(shape=(5,1)) \n",
    "\n",
    "output_tensor = I(input_1)  \n",
    "\n",
    "model123 = Model([input_1], output_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.randint(1,10,[1,5,1])\n",
    "\n",
    "y=model123.predict(x)\n",
    "\n",
    "print(x ,'\\n\\n')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mlayers([input_ah,vpx])\n",
    "\n",
    "Mlayers = layers.Multiply(name='Multiply',trainable=False)\n",
    "\n",
    "constants = np.array([1,2,3,4,5],dtype=np.float32).reshape(5,1)\n",
    "\n",
    "fixed_input0 = Input(shape=(5,1),tensor=tf.constant(constants))\n",
    "input_1 = Input(shape=(5,1)) \n",
    "\n",
    "output_tensor = Mlayers([fixed_input0,input_1])  \n",
    "\n",
    "model = Model([input_1,fixed_input0], output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.randint(1,5,[2,5,1])\n",
    "\n",
    "y=model.predict(x)\n",
    "\n",
    "print(x ,'\\n\\n')\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
